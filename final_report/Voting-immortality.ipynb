{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e9dd29c-d6d8-4d8e-9e04-d61a5344043d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "rs=np.random.RandomState(42)\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import make_column_transformer,make_column_selector\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import SimpleImputer, IterativeImputer,KNNImputer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier, LogisticRegressionCV, RidgeClassifierCV\n",
    "from sklearn.neighbors import KNeighborsClassifier, RadiusNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, BaggingClassifier, RandomForestClassifier, HistGradientBoostingClassifier\n",
    "from sklearn.ensemble import StackingClassifier,VotingClassifier\n",
    "from sklearn.metrics import classification_report, f1_score, recall_score, precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7822bba-a729-436d-834d-c8de38ddcaa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data01.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be459601-8f8d-4b44-a0f4-3f70bab14fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.info(verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "269301db-de5e-4509-8269-35465121be88",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=\"ID\")\n",
    "df = df.dropna(subset=[\"outcome\"])\n",
    "df[\"outcome\"] = df[\"outcome\"].astype(\"int\")\n",
    "df[\"EF\"] = df[\"EF\"].astype(\"float\")\n",
    "#df.info(verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ddce5d7-625f-4519-a9a3-fb3e62c1c4b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mortality ratio in train set: 0.127\n",
      "mortality ratio in test set: 0.169\n"
     ]
    }
   ],
   "source": [
    "y = df[\"outcome\"]\n",
    "x = df.drop(columns=\"outcome\")\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=rs,shuffle=True)\n",
    "print(f\"mortality ratio in train set: {y_train.sum()/len(y_train):.3f}\")\n",
    "print(f\"mortality ratio in test set: {y_test.sum()/len(y_test):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "367fee14-170d-4ce7-a591-6e48c847d966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(119, 50) (821, 50)\n"
     ]
    }
   ],
   "source": [
    "# resample the train dataset by simply oversampling the mortality data \n",
    "# TODO: use more complex approaches to augment the data e.g. LinearInterpolation, SMOTE, CTGAN \n",
    "yx_train = pd.concat([y_train,x_train],axis=1)\n",
    "yx_train_pos = yx_train[yx_train[\"outcome\"]==1]\n",
    "yx_train_neg = yx_train[yx_train[\"outcome\"]==0]\n",
    "print(yx_train_pos.shape,yx_train_neg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37a01ecc-6f61-493e-83ae-c1f9928afcc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_y_train_set=[]\n",
    "rs_x_train_set=[]\n",
    "for n in range(1,10):\n",
    "    oversampled_yx_train_pos = pd.concat([yx_train_pos for i in range(n)])\n",
    "    resampled_yx_train = pd.concat([oversampled_yx_train_pos,yx_train_neg])\n",
    "    rs_y_train = resampled_yx_train[\"outcome\"]\n",
    "    rs_x_train = resampled_yx_train.drop(columns=\"outcome\")\n",
    "    rs_y_train_set.append(rs_y_train)\n",
    "    rs_x_train_set.append(pd.DataFrame(rs_x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "887c61d4-766d-4941-8216-b50e2e037ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: try more preprocessing strategies and combinations\n",
    "imputer1 = SimpleImputer(strategy='mean')\n",
    "imputer2 = SimpleImputer(strategy='median')\n",
    "imputer3 = SimpleImputer(strategy='most_frequent')\n",
    "imputer4 = IterativeImputer(max_iter=10, random_state=rs)\n",
    "imputer5 = KNNImputer(n_neighbors=2, weights=\"uniform\")\n",
    "\n",
    "scaler1 = StandardScaler()\n",
    "scaler2 = MinMaxScaler(feature_range=(-1,1))\n",
    "\n",
    "preprocess_pipe = make_column_transformer((make_pipeline(scaler1,imputer4), make_column_selector(dtype_include=np.float64)),\n",
    "                                          ((make_pipeline(scaler2,imputer3), make_column_selector(dtype_include=np.int64))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a6732f6-8160-48c6-b4d7-fe2c37232782",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_sample = rs_x_train_set[0] # ???\n",
    "preprocess_pipe.fit(x_train_sample)\n",
    "rs_x_train_set = [preprocess_pipe.transform(x_sample) for x_sample in rs_x_train_set]\n",
    "x_test = preprocess_pipe.transform(pd.DataFrame(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b10408d-1613-4d63-9c19-4ac9e2f37b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model,x=x_test,y=y_test):\n",
    "    y_pred = model.predict(x)\n",
    "    print(classification_report(y,y_pred))\n",
    "\n",
    "def evaluate_label_ratio(model,x=x_test,y=y_test):\n",
    "    f1=[]\n",
    "    rec=[]\n",
    "    pre=[]\n",
    "    for y_train,x_train in zip(rs_y_train_set,rs_x_train_set):\n",
    "        model.fit(x_train,y_train)\n",
    "        y_pred = model.predict(x)\n",
    "        f1.append(f\"{f1_score(y,y_pred):.3f}\")\n",
    "        rec.append(f\"{recall_score(y,y_pred):.3f}\")\n",
    "        pre.append(f\"{precision_score(y,y_pred):.3f}\")\n",
    "    print(\"f1\",f1,max(f1,key=float))\n",
    "    print(\"rec\",rec)\n",
    "    print(\"pre\",pre)\n",
    "import time\n",
    "def statistic_evaluate(model0,os_ration=3,rs=rs,n=42):\n",
    "    t=[]\n",
    "    outcome=[]\n",
    "    for i in range(n):\n",
    "        model = eval(model0)\n",
    "        t0=time.time()\n",
    "        model.fit(rs_x_train_set[os_ration],rs_y_train_set[os_ration])\n",
    "        t.append(time.time()-t0)\n",
    "        y_pred = model.predict(x_test)\n",
    "        outcome.append(f1_score(y_test,y_pred))\n",
    "        if i==5 and np.std(outcome,ddof=1)<1e-3:\n",
    "            print(\"early stop\")\n",
    "            break\n",
    "    return np.mean(outcome),np.std(outcome,ddof=1),np.mean(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43793232-8266-424e-879e-d19f83c94382",
   "metadata": {},
   "outputs": [],
   "source": [
    "models={\n",
    "       \"LR1\":'LogisticRegression(penalty=\"l1\",solver=\"saga\",random_state=rs)',\n",
    "       \"LR2\":'LogisticRegression(penalty=\"l2\",solver=\"saga\",random_state=rs)',\n",
    "       \"LR3\":'LogisticRegression(penalty=\"elasticnet\",l1_ratio=0.5,solver=\"saga\",random_state=rs)',\n",
    "       \"KNN1\":'KNeighborsClassifier(n_neighbors=3,weights=\"uniform\")',\n",
    "       \"KNN2\":'KNeighborsClassifier(n_neighbors=7,weights=\"uniform\")',\n",
    "       \"MLP1\":'MLPClassifier([24],activation=\"tanh\",solver=\"adam\",alpha=1,random_state=rs,early_stopping=True,validation_fraction=0.2,n_iter_no_change=10)',\n",
    "       \"MLP2\":'MLPClassifier([24,12],activation=\"tanh\",solver=\"adam\",alpha=1,random_state=rs,early_stopping=True,validation_fraction=0.2,n_iter_no_change=10)',\n",
    "       \"MLP3\":'MLPClassifier([24,12,6],activation=\"tanh\",solver=\"adam\",alpha=1,random_state=rs,early_stopping=True,validation_fraction=0.2,n_iter_no_change=10)',\n",
    "       \"SVM1\":'SVC(C=1.0,kernel=\"rbf\",random_state=rs)',\n",
    "       \"SVM2\":'SVC(C=1.0,kernel=\"linear\",random_state=rs)',\n",
    "       \"SVM3\":'SVC(C=1.0,kernel=\"poly\",degree=3,random_state=rs)',\n",
    "       \"SVM4\":'SVC(C=1.0,kernel=\"sigmoid\",random_state=rs,)',\n",
    "       \"DT\":'DecisionTreeClassifier(criterion=\"entropy\",max_depth=18,min_samples_split=5,random_state=rs)',\n",
    "       \"RF\":'RandomForestClassifier(n_estimators=30,max_depth=18,min_samples_split=5,random_state=rs)',\n",
    "       \"AdaB\":'AdaBoostClassifier(estimator=LogisticRegression(random_state=rs),random_state=rs)',\n",
    "       \"Bag\":'BaggingClassifier(estimator=LogisticRegression(random_state=rs),random_state=rs)',\n",
    "       }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd892a22-2b48-4b4f-917f-95d339e6006f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "early stop\n",
      "0.5205479452054794 0.0 0.7701276540756226\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "\n",
    "outcomes={}\n",
    "model='''VotingClassifier([(\"LR1\",LogisticRegression(penalty=\"l2\",solver=\"saga\",random_state=rs)),\n",
    "                          (\"LR2\",LogisticRegression(penalty=\"l2\",solver=\"saga\",random_state=rs)),\n",
    "                          (\"MLP1\",MLPClassifier([24],activation=\"tanh\",solver=\"adam\",alpha=1,random_state=rs,early_stopping=True,validation_fraction=0.2,n_iter_no_change=10,max_iter=80)),\n",
    "                          (\"MLP2\",MLPClassifier([24],activation=\"tanh\",solver=\"adam\",alpha=1,random_state=rs,early_stopping=True,validation_fraction=0.2,n_iter_no_change=10,max_iter=80)),\n",
    "                          (\"MLP3\",MLPClassifier([24],activation=\"tanh\",solver=\"adam\",alpha=1,random_state=rs,early_stopping=True,validation_fraction=0.2,n_iter_no_change=10,max_iter=80)),\n",
    "                          \n",
    "                          (\"SVM1\",SVC(C=1.0,kernel=\"rbf\",random_state=rs)),\n",
    "                          (\"SVM2\",SVC(C=1.0,kernel=\"poly\",degree=3,random_state=rs)),\n",
    "                          (\"SVM3\",SVC(C=1.0,kernel=\"poly\",degree=4,random_state=rs)),\n",
    "                          (\"NB\",make_pipeline(KBinsDiscretizer(n_bins=5,encode=\"ordinal\"),CategoricalNB()))\n",
    "                          ]\n",
    "                         )'''\n",
    "m,s,tm=statistic_evaluate(model,os_ration=3,rs=rs,n=24)\n",
    "print(m,s,tm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e33160b-e554-4aad-a965-bac61e09fc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858e4711-506d-4365-8894-967158773dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "tm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e185ed3-c772-45e4-93b2-db328fc5c4f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
